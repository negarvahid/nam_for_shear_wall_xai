{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7XpkvN_9gRn",
        "outputId": "575e2bdb-69f8-481a-952e-1c3d71a093e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openpyxl in ./.venv/lib/python3.11/site-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in ./.venv/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: shap in ./.venv/lib/python3.11/site-packages (0.47.2)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from shap) (2.2.6)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from shap) (1.15.3)\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from shap) (1.6.1)\n",
            "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from shap) (2.2.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in ./.venv/lib/python3.11/site-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in ./.venv/lib/python3.11/site-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in ./.venv/lib/python3.11/site-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in ./.venv/lib/python3.11/site-packages (from shap) (0.61.2)\n",
            "Requirement already satisfied: cloudpickle in ./.venv/lib/python3.11/site-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.11/site-packages (from shap) (4.13.2)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in ./.venv/lib/python3.11/site-packages (from numba>=0.54->shap) (0.44.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->shap) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas->shap) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->shap) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->shap) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: xgboost in ./.venv/lib/python3.11/site-packages (3.0.2)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from xgboost) (2.2.6)\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from xgboost) (1.15.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: torch in ./.venv/lib/python3.11/site-packages (2.7.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in ./.venv/lib/python3.11/site-packages (from torch) (2025.5.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: matplotlib in ./.venv/lib/python3.11/site-packages (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.2.6)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: seaborn in ./.venv/lib/python3.11/site-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in ./.venv/lib/python3.11/site-packages (from seaborn) (2.2.6)\n",
            "Requirement already satisfied: pandas>=1.2 in ./.venv/lib/python3.11/site-packages (from seaborn) (2.2.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in ./.venv/lib/python3.11/site-packages (from seaborn) (3.10.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (1.15.3)\n",
            "Requirement already satisfied: numpy<2.5,>=1.23.5 in ./.venv/lib/python3.11/site-packages (from scipy) (2.2.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (1.6.1)\n",
            "Requirement already satisfied: numpy>=1.19.5 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (2.2.6)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install openpyxl\n",
        "%pip install shap\n",
        "%pip install xgboost\n",
        "%pip install torch\n",
        "%pip install matplotlib\n",
        "%pip install seaborn\n",
        "%pip install scipy\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0HuXkOOfzq-Q"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import shap\n",
        "import joblib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import QuantileTransformer\n",
        "from scipy import stats\n",
        "import json\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TVtWF8SqAebG"
      },
      "outputs": [],
      "source": [
        "from nam_analysis import NAMAnalyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rZFO2Y4uA0cG"
      },
      "outputs": [],
      "source": [
        "FEATURE_DICT = {\n",
        "    'lw': 'Length',\n",
        "    'hw': 'Height',\n",
        "    'tw': 'Thickness',\n",
        "    'f′c': 'Concrete compressive strength',\n",
        "    'fyt': 'Transverse web reinforcement yield strength',\n",
        "    'fysh': 'Transverse boundary reinforcement yield strength',\n",
        "    'fyl': 'Vertical web reinforcement yield strength',\n",
        "    'fybl': 'Vertical boundary reinforcement yield strength',\n",
        "    'ρt': 'Transverse web reinforcement ratio',\n",
        "    'ρsh': 'Transverse boundary reinforcement ratio',\n",
        "    'ρl': 'Vertical web reinforcement ratio',\n",
        "    'ρbl': 'Vertical boundary reinforcement ratio',\n",
        "    'P/(Agf′c)': 'Axial Load Ratio',\n",
        "    'b0': 'Boundary element depth',\n",
        "    'db': 'Boundary element length',\n",
        "    's/db': 'Hoop spacing / Boundary element length',\n",
        "    'AR': 'Aspect ratio',\n",
        "    'M/Vlw': 'Shear span ratio'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-QJ1gAyByk_",
        "outputId": "7beada08-c7d5-4406-cef0-952f525ab0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original dataframe shape: (312, 25)\n",
            "\n",
            "Missing values in features:\n",
            "fysh       : 100 (32.1%)\n",
            "fybl       : 29 (9.3%)\n",
            "ρsh        : 96 (30.8%)\n",
            "ρbl        : 32 (10.3%)\n",
            "\n",
            "fysh:\n",
            "  Original skewness: 2.1691698429431523\n",
            "  Transformation results:\n",
            "    log1p: -1.37\n",
            "    power: -0.41\n",
            "    rank: 0.00\n",
            "  Selected: rank (skewness: 0.00)\n",
            "\n",
            "ρsh:\n",
            "  Original skewness: 5.072272455267313\n",
            "  Transformation results:\n",
            "    log1p: 4.87\n",
            "    power: 0.43\n",
            "    rank: 0.00\n",
            "  Selected: rank (skewness: 0.00)\n",
            "\n",
            "Feature Transformations:\n",
            "\n",
            "Analyzing ρsh distribution before transformation:\n",
            "\n",
            "Detailed Analysis of ρsh:\n",
            "Count: 216\n",
            "Missing values: 96\n",
            "Unique values: 113\n",
            "Zeros: 0 (0.0%)\n",
            "\n",
            "Central Tendency:\n",
            "Mean: 0.009859\n",
            "Median: 0.008177\n",
            "Std Dev: 0.009038\n",
            "\n",
            "Shape:\n",
            "Skewness: 5.07\n",
            "Kurtosis: 40.30\n",
            "\n",
            "Range:\n",
            "Min: 0.000950\n",
            "Max: 0.095700\n",
            "\n",
            "Percentiles:\n",
            "p0: 0.000950\n",
            "p1: 0.001340\n",
            "p5: 0.002248\n",
            "p10: 0.002513\n",
            "p25: 0.005309\n",
            "p50: 0.008177\n",
            "p75: 0.011166\n",
            "p90: 0.016956\n",
            "p95: 0.023020\n",
            "p99: 0.042834\n",
            "p100: 0.095700\n",
            "\n",
            "Feature Dictionary (Abbreviation -> Full Name):\n",
            "lw         : Length\n",
            "hw         : Height\n",
            "tw         : Thickness\n",
            "f′c        : Concrete compressive strength\n",
            "fyt        : Transverse web reinforcement yield strength\n",
            "fysh       : Transverse boundary reinforcement yield strength\n",
            "fyl        : Vertical web reinforcement yield strength\n",
            "fybl       : Vertical boundary reinforcement yield strength\n",
            "ρt         : Transverse web reinforcement ratio\n",
            "ρsh        : Transverse boundary reinforcement ratio\n",
            "ρl         : Vertical web reinforcement ratio\n",
            "ρbl        : Vertical boundary reinforcement ratio\n",
            "P/(Agf′c)  : Axial Load Ratio\n",
            "b0         : Boundary element depth\n",
            "db         : Boundary element length\n",
            "s/db       : Hoop spacing / Boundary element length\n",
            "AR         : Aspect ratio\n",
            "M/Vlw      : Shear span ratio\n",
            "\n",
            "Data shapes:\n",
            "Training set (X_train): (249, 18)\n",
            "Testing set (X_test): (63, 18)\n",
            "Training labels (y_train): (249, 1)\n",
            "Testing labels (y_test): (63, 1)\n",
            "\n",
            "Feature ranges after normalization (training set):\n",
            "lw         : [-1.00, 1.00]\n",
            "hw         : [-1.00, 1.00]\n",
            "tw         : [-1.00, 1.00]\n",
            "f′c        : [-1.00, 1.00]\n",
            "fyt        : [-1.00, 1.00]\n",
            "fysh       : [-1.00, 1.00]\n",
            "fyl        : [-1.00, 1.00]\n",
            "fybl       : [-1.00, 1.00]\n",
            "ρt         : [-1.00, 1.00]\n",
            "ρsh        : [-1.00, 1.00]\n",
            "ρl         : [-1.00, 1.00]\n",
            "ρbl        : [-1.00, 1.00]\n",
            "P/(Agf′c)  : [-1.00, 1.00]\n",
            "b0         : [-1.00, 1.00]\n",
            "db         : [-1.00, 1.00]\n",
            "s/db       : [-1.00, 1.00]\n",
            "AR         : [-1.00, 1.00]\n",
            "M/Vlw      : [-1.00, 1.00]\n",
            "\n",
            "Target range after normalization (training set):\n",
            "NCDE      : [-1.00, 1.00]\n",
            "\n",
            "First few rows of normalized training data:\n",
            "           lw      hw        tw       f′c       fyt      fysh       fyl  \\\n",
            "111 -0.612903 -0.4000 -0.313869 -0.863354 -0.526115 -0.009569 -0.526115   \n",
            "208 -0.029032  0.6288 -0.448175 -0.332059 -0.331185  0.229665 -0.331185   \n",
            "145 -0.354839 -0.5200 -0.605839  0.273770  0.612739 -0.354067  0.620382   \n",
            "203 -0.290323  0.2000  0.270073 -0.486861 -0.357962  0.181818 -0.357962   \n",
            "78  -0.095484  0.3960 -0.532847 -0.452461 -0.250955  0.411483 -0.480255   \n",
            "\n",
            "         fybl        ρt       ρsh        ρl       ρbl  P/(Agf′c)        b0  \\\n",
            "111 -0.785495 -0.767229 -0.023256 -0.920379  0.845629  -1.000000 -0.928276   \n",
            "208 -0.724549 -0.860378 -0.023256 -0.926149 -0.906450  -1.000000 -0.648276   \n",
            "145 -0.482465 -0.075325  0.544186 -0.334913 -0.704473  -0.440468 -0.793103   \n",
            "203 -0.673136 -0.552665 -0.362791 -0.946709 -1.000000  -0.720234 -0.793103   \n",
            "78  -0.754852  0.034623  0.641860  0.729842 -0.467601  -0.893613 -0.944828   \n",
            "\n",
            "           db      s/db        AR     M/Vlw  \n",
            "111 -0.598425 -0.247059 -0.114058 -0.763668  \n",
            "208  0.200787 -0.995719  0.098143 -0.273369  \n",
            "145 -0.212598 -0.990400 -0.530883 -0.410935  \n",
            "203 -0.212598 -0.984640  0.062776 -0.293474  \n",
            "78  -0.677165 -0.978927 -0.000421 -0.336861  \n",
            "\n",
            "First few rows of normalized training labels (NCDE):\n",
            "         NCDE\n",
            "111 -0.887815\n",
            "208 -0.492229\n",
            "145 -0.660321\n",
            "203 -0.715968\n",
            "78  -0.681096\n",
            "\n",
            "Feature Statistics:\n",
            "               mean       std       min       max      skew   kurtosis\n",
            "lw        -0.352885  0.388193 -1.000000  1.000000  1.216663   1.717661\n",
            "hw        -0.330730  0.479448 -1.000000  3.600000  2.327667  13.667403\n",
            "tw        -0.230067  0.330108 -1.000000  1.000000  0.449187  -0.501191\n",
            "f′c       -0.460248  0.375978 -1.000000  1.000000  1.795692   3.689697\n",
            "fyt       -0.298218  0.333924 -1.000000  1.000000  0.846475   1.537292\n",
            "fysh      -0.006318  0.483409 -1.000000  1.000000  0.010377  -0.338786\n",
            "fyl       -0.278302  0.329516 -1.000000  1.000000  0.999973   1.909749\n",
            "fybl      -0.626374  0.199719 -1.000000  1.000000  2.214792  13.880487\n",
            "ρt        -0.611000  0.279614 -1.002641  1.000000  1.696370   5.556095\n",
            "ρsh       -0.007156  0.483391 -1.000000  1.000000  0.044750  -0.388075\n",
            "ρl        -0.715882  0.243084 -1.000000  1.000000  2.584816  11.774368\n",
            "ρbl       -0.509668  0.457474 -1.000000  1.000000  1.529157   1.392031\n",
            "P/(Agf′c) -0.593558  0.465544 -1.000000  1.000000  1.736983   3.178958\n",
            "b0        -0.784042  0.222026 -1.000000  1.000000  4.308101  27.970313\n",
            "db        -0.306800  0.391542 -1.000000  1.325984  0.675563   1.612299\n",
            "s/db      -0.848991  0.283247 -1.000000  1.000000  3.311556  15.589486\n",
            "AR        -0.288611  0.420676 -1.000000  2.742502  1.349713   7.910063\n",
            "M/Vlw     -0.498012  0.319806 -1.000000  1.486772  1.316477   5.473075\n",
            "\n",
            "Highly correlated feature pairs (|r| > 0.7):\n",
            "fyt - fyl: 0.842\n",
            "AR - M/Vlw: 0.861\n"
          ]
        }
      ],
      "source": [
        "def sanitize_filename(filename):\n",
        "    \"\"\"Convert a string into a valid filename by removing invalid characters.\"\"\"\n",
        "    # Replace invalid characters with underscores\n",
        "    filename = re.sub(r'[/\\\\?%*:|\"<>()\\'{}]', '_', filename)\n",
        "    # Replace Greek letters and special characters\n",
        "    filename = filename.replace('ρ', 'rho')\n",
        "    filename = filename.replace('′', '_prime_')\n",
        "    # Remove multiple underscores\n",
        "    filename = re.sub(r'_+', '_', filename)\n",
        "    # Remove leading/trailing underscores\n",
        "    filename = filename.strip('_')\n",
        "    return filename\n",
        "\n",
        "def analyze_and_transform_skewed_features(data, features=['fysh', 'ρsh'], threshold=1.0, high_skew_threshold=3.0):\n",
        "    \"\"\"\n",
        "    Analyze and transform skewed features using various transformations.\n",
        "    \"\"\"\n",
        "    transformed_data = data.copy()\n",
        "    transformations = {}\n",
        "\n",
        "    for feature in features:\n",
        "        print(f\"\\n{feature}:\")\n",
        "        # Calculate skewness\n",
        "        original_skew = data[feature].skew()\n",
        "        print(f\"  Original skewness: {original_skew}\")\n",
        "\n",
        "        # Apply transformations if skewed\n",
        "        if abs(original_skew) > threshold:\n",
        "            # Prepare data\n",
        "            min_value = data[feature].min()\n",
        "            max_value = data[feature].max()\n",
        "            range_value = max_value - min_value\n",
        "            offset = -min_value + range_value * 0.01\n",
        "\n",
        "            print(\"  Transformation results:\")\n",
        "            \n",
        "            # Try different transformations\n",
        "            transformations_to_try = []\n",
        "\n",
        "            # 1. Log transformation\n",
        "            log_data = np.log1p(data[feature] + offset)\n",
        "            log_skew = log_data.skew()\n",
        "            print(f\"    log1p: {log_skew:.2f}\")\n",
        "            transformations_to_try.append(('log1p', log_data, log_skew))\n",
        "\n",
        "            # 2. Power transformation (x^0.2)\n",
        "            power_data = np.power(data[feature] + offset, 0.2)\n",
        "            power_skew = power_data.skew()\n",
        "            print(f\"    power: {power_skew:.2f}\")\n",
        "            transformations_to_try.append(('power', power_data, power_skew))\n",
        "\n",
        "            # 3. Rank (percentile) transformation\n",
        "            rank_data = data[feature].rank(pct=True)\n",
        "            rank_skew = rank_data.skew()\n",
        "            print(f\"    rank: {rank_skew:.2f}\")\n",
        "            transformations_to_try.append(('rank', rank_data, rank_skew))\n",
        "\n",
        "            # Choose the best transformation (lowest absolute skewness)\n",
        "            best_transform = min(transformations_to_try, key=lambda x: abs(x[2]))\n",
        "            transform_type, transformed_values, new_skew = best_transform\n",
        "            print(f\"  Selected: {transform_type} (skewness: {new_skew:.2f})\")\n",
        "\n",
        "            # Apply the best transformation\n",
        "            transformed_data[feature] = transformed_values\n",
        "\n",
        "            transformations[feature] = {\n",
        "                'type': transform_type,\n",
        "                'original_skew': original_skew,\n",
        "                'transformed_skew': new_skew\n",
        "            }\n",
        "\n",
        "    return transformed_data, transformations\n",
        "\n",
        "\n",
        "def load_and_process_data(excel_path=\"Database_ShearWall.xlsx\", verbose=True, test_size=0.2, random_state=42):\n",
        "    \"\"\"\n",
        "    Load and process the shear wall database.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    excel_path : str, default=\"Database_ShearWall.xlsx\"\n",
        "        Path to the Excel file containing the database\n",
        "    verbose : bool, default=True\n",
        "        Whether to print information about the data\n",
        "    test_size : float, default=0.2\n",
        "        Proportion of the dataset to include in the test split\n",
        "    random_state : int, default=42\n",
        "        Random state for reproducibility\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary containing:\n",
        "        - X_train, X_test: Training/testing features (normalized to [-1, 1])\n",
        "        - y_train, y_test: Training/testing targets (normalized to [-1, 1])\n",
        "        - feature_names: List of feature names\n",
        "        - x_scaler: Fitted MinMaxScaler for features\n",
        "        - y_scaler: Fitted MinMaxScaler for target\n",
        "        - transformations: Dictionary containing transformation info\n",
        "    \"\"\"\n",
        "    # Input validation\n",
        "    if not os.path.exists(excel_path):\n",
        "        raise FileNotFoundError(f\"Excel file not found: {excel_path}\")\n",
        "\n",
        "    # List of features in order\n",
        "    feature_names = list(FEATURE_DICT.keys())\n",
        "    output_name = 'NCDE'  # The target variable\n",
        "\n",
        "    try:\n",
        "        # Read the database, skipping the first 3 rows which are headers\n",
        "        df = pd.read_excel(excel_path, skiprows=3)\n",
        "\n",
        "        if verbose:\n",
        "            print(\"Original dataframe shape:\", df.shape)\n",
        "\n",
        "        # Remove the metadata columns (first 3 columns) and the last 3 columns\n",
        "        df_processed = df.iloc[:, 3:-3]\n",
        "\n",
        "        # Validate number of columns\n",
        "        expected_cols = len(feature_names) + 1  # features + NCDE\n",
        "        if df_processed.shape[1] != expected_cols:\n",
        "            raise ValueError(f\"Expected {expected_cols} columns but got {df_processed.shape[1]}\")\n",
        "\n",
        "        # Extract features and target\n",
        "        X = df_processed.iloc[:, :18]\n",
        "        y = df_processed.iloc[:, 18:19]  # NCDE column\n",
        "\n",
        "        # Rename columns for clarity\n",
        "        X.columns = feature_names\n",
        "        y.columns = [output_name]\n",
        "\n",
        "        # Convert data to numeric, replacing '-' with NaN\n",
        "        X = X.replace({'-': None}).astype(float)\n",
        "        y = y.astype(float)\n",
        "\n",
        "        # Print information about missing values if verbose\n",
        "        if verbose:\n",
        "            print(\"\\nMissing values in features:\")\n",
        "            missing_values = X.isnull().sum()\n",
        "            for feature, count in missing_values.items():\n",
        "                if count > 0:\n",
        "                    print(f\"{feature:10} : {count} ({count/len(X)*100:.1f}%)\")\n",
        "\n",
        "        # Validate target variable\n",
        "        if y.isnull().any().any():\n",
        "            raise ValueError(\"Target variable (NCDE) contains missing values\")\n",
        "\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"Error loading data: {str(e)}\")\n",
        "\n",
        "    # Analyze and transform skewed features\n",
        "    skewed_features = ['fysh', 'ρsh']\n",
        "    X_transformed, transformations = analyze_and_transform_skewed_features(X, features=skewed_features)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nFeature Transformations:\")\n",
        "        for feature, info in transformations.items():\n",
        "            if info['type'] == 'log1p':\n",
        "                print(f\"{feature}:\")\n",
        "                print(f\"  Original skewness: {info['original_skew']:.2f}\")\n",
        "                print(f\"  After log transform: {info['transformed_skew']:.2f}\")\n",
        "\n",
        "    # Analyze ρsh distribution before any transformations\n",
        "    print(\"\\nAnalyzing ρsh distribution before transformation:\")\n",
        "    rho_sh_stats = analyze_feature_distribution(X, 'ρsh')\n",
        "\n",
        "    # Split the transformed data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X_transformed, y, test_size=test_size, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Compute medians from training data only\n",
        "    train_medians = X_train.median()\n",
        "\n",
        "    # Fill missing values in both sets using training medians\n",
        "    X_train_filled = X_train.fillna(train_medians)\n",
        "    X_test_filled = X_test.fillna(train_medians)\n",
        "\n",
        "    # Initialize and fit scalers on training data only\n",
        "    x_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "    y_scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "\n",
        "    # Fit scalers on training data and transform both sets\n",
        "    X_train_normalized = pd.DataFrame(\n",
        "        x_scaler.fit_transform(X_train_filled),\n",
        "        columns=X_train_filled.columns,\n",
        "        index=X_train_filled.index\n",
        "    )\n",
        "\n",
        "    X_test_normalized = pd.DataFrame(\n",
        "        x_scaler.transform(X_test_filled),\n",
        "        columns=X_test_filled.columns,\n",
        "        index=X_test_filled.index\n",
        "    )\n",
        "\n",
        "    y_train_normalized = pd.DataFrame(\n",
        "        y_scaler.fit_transform(y_train),\n",
        "        columns=y_train.columns,\n",
        "        index=y_train.index\n",
        "    )\n",
        "\n",
        "    y_test_normalized = pd.DataFrame(\n",
        "        y_scaler.transform(y_test),\n",
        "        columns=y_test.columns,\n",
        "        index=y_test.index\n",
        "    )\n",
        "\n",
        "    if verbose:\n",
        "        print(\"\\nFeature Dictionary (Abbreviation -> Full Name):\")\n",
        "        for abbr, full_name in FEATURE_DICT.items():\n",
        "            print(f\"{abbr:10} : {full_name}\")\n",
        "\n",
        "        print(\"\\nData shapes:\")\n",
        "        print(\"Training set (X_train):\", X_train_normalized.shape)\n",
        "        print(\"Testing set (X_test):\", X_test_normalized.shape)\n",
        "        print(\"Training labels (y_train):\", y_train_normalized.shape)\n",
        "        print(\"Testing labels (y_test):\", y_test_normalized.shape)\n",
        "\n",
        "        print(\"\\nFeature ranges after normalization (training set):\")\n",
        "        for col in X_train_normalized.columns:\n",
        "            print(f\"{col:10} : [{X_train_normalized[col].min():.2f}, {X_train_normalized[col].max():.2f}]\")\n",
        "\n",
        "        print(\"\\nTarget range after normalization (training set):\")\n",
        "        print(f\"NCDE      : [{y_train_normalized[output_name].min():.2f}, {y_train_normalized[output_name].max():.2f}]\")\n",
        "\n",
        "        print(\"\\nFirst few rows of normalized training data:\")\n",
        "        print(X_train_normalized.head())\n",
        "        print(\"\\nFirst few rows of normalized training labels (NCDE):\")\n",
        "        print(y_train_normalized.head())\n",
        "\n",
        "    return {\n",
        "        'X_train': X_train_normalized,\n",
        "        'X_test': X_test_normalized,\n",
        "        'y_train': y_train_normalized,\n",
        "        'y_test': y_test_normalized,\n",
        "        'feature_names': feature_names,\n",
        "        'x_scaler': x_scaler,\n",
        "        'y_scaler': y_scaler,\n",
        "        'transformations': transformations\n",
        "    }\n",
        "\n",
        "def analyze_features(data_dict, save_plots=True, output_dir=\"plots\"):\n",
        "    \"\"\"\n",
        "    Perform comprehensive analysis of features including distributions,\n",
        "    correlations, and basic statistics.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    data_dict : dict\n",
        "        Dictionary containing X, y, and metadata from load_and_process_data()\n",
        "    save_plots : bool, default=True\n",
        "        Whether to save plots to files\n",
        "    output_dir : str, default=\"plots\"\n",
        "        Directory to save plots if save_plots is True\n",
        "    \"\"\"\n",
        "    # Extract X and y from the data dictionary\n",
        "    X = pd.concat([data_dict['X_train'], data_dict['X_test']])\n",
        "    y = pd.concat([data_dict['y_train'], data_dict['y_test']])\n",
        "    feature_names = data_dict['feature_names']\n",
        "\n",
        "    # Create output directory if it doesn't exist\n",
        "    if save_plots and not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Convert any string values to numeric, replacing non-numeric with NaN\n",
        "    X = X.apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # Basic statistics\n",
        "    stats_df = pd.DataFrame({\n",
        "        'mean': X.mean(),\n",
        "        'std': X.std(),\n",
        "        'min': X.min(),\n",
        "        'max': X.max(),\n",
        "        'skew': X.skew(),\n",
        "        'kurtosis': X.kurtosis()\n",
        "    })\n",
        "    print(\"\\nFeature Statistics:\")\n",
        "    print(stats_df)\n",
        "\n",
        "    # Create box plots for all features\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    sns.boxplot(data=X)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('Box Plots of All Features')\n",
        "    plt.tight_layout()\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{output_dir}/feature_boxplots.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Create statistical summary plots\n",
        "    for feature in feature_names:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Create bar plot for statistics\n",
        "        stats_values = [\n",
        "            stats_df.loc[feature, 'mean'],\n",
        "            stats_df.loc[feature, 'std'],\n",
        "            stats_df.loc[feature, 'min'],\n",
        "            stats_df.loc[feature, 'max']\n",
        "        ]\n",
        "        stats_labels = ['Mean', 'Std Dev', 'Min', 'Max']\n",
        "\n",
        "        # Create bar plot\n",
        "        bars = plt.bar(stats_labels, stats_values)\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.2f}',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "        plt.title(f'Statistical Summary of {feature}\\n({FEATURE_DICT[feature]})')\n",
        "        plt.ylabel('Value')\n",
        "\n",
        "        if save_plots:\n",
        "            safe_filename = sanitize_filename(feature)\n",
        "            plt.savefig(f\"{output_dir}/stats_summary_{safe_filename}.png\", bbox_inches='tight', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    # Create a normalized parallel coordinates plot\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    # Normalize the data for better visualization\n",
        "    X_norm = (X - X.min()) / (X.max() - X.min())\n",
        "    pd.plotting.parallel_coordinates(\n",
        "        pd.concat([X_norm, pd.Series(np.zeros(len(X)), name='group')], axis=1),\n",
        "        'group',\n",
        "        alpha=0.1\n",
        "    )\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('Normalized Parallel Coordinates Plot of All Features')\n",
        "    plt.tight_layout()\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{output_dir}/parallel_coordinates.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Create statistical overview heatmap\n",
        "    # Normalize statistics for better visualization\n",
        "    stats_for_heatmap = stats_df.copy()\n",
        "    for col in stats_for_heatmap.columns:\n",
        "        stats_for_heatmap[col] = (stats_for_heatmap[col] - stats_for_heatmap[col].min()) / \\\n",
        "                                (stats_for_heatmap[col].max() - stats_for_heatmap[col].min())\n",
        "\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(stats_for_heatmap.T, annot=True, fmt='.2f', cmap='YlOrRd')\n",
        "    plt.title('Statistical Measures Heatmap (Normalized)')\n",
        "    plt.tight_layout()\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{output_dir}/statistics_heatmap.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Individual Feature Distributions\n",
        "    for feature in feature_names:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.histplot(X[feature].dropna(), kde=True)\n",
        "        plt.title(f'Distribution of {feature}')\n",
        "        plt.xlabel(FEATURE_DICT[feature])\n",
        "        if save_plots:\n",
        "            safe_filename = sanitize_filename(feature)\n",
        "            plt.savefig(f\"{output_dir}/distribution_{safe_filename}.png\", bbox_inches='tight', dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "    # NCDE Distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(y['NCDE'], kde=True)\n",
        "    plt.title('Distribution of NCDE (Output)')\n",
        "    plt.xlabel('NCDE')\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{output_dir}/distribution_NCDE_output.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Correlations\n",
        "    # Features vs NCDE\n",
        "    feature_ncde_corr = pd.DataFrame(index=feature_names, columns=['correlation'])\n",
        "    for feature in feature_names:\n",
        "        # Drop any NaN values for correlation calculation\n",
        "        valid_data = pd.concat([X[feature], y['NCDE']], axis=1).dropna()\n",
        "        if not valid_data.empty:\n",
        "            feature_ncde_corr.loc[feature, 'correlation'] = stats.pearsonr(\n",
        "                valid_data[feature],\n",
        "                valid_data['NCDE']\n",
        "            )[0]\n",
        "\n",
        "    # Plot feature-NCDE correlations\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    sns.barplot(x=feature_ncde_corr.index, y='correlation', data=feature_ncde_corr)\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.title('Feature Correlations with NCDE')\n",
        "    plt.tight_layout()\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{output_dir}/correlations_features_vs_NCDE.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Inter-feature correlations heatmap\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(X.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "    plt.title('Inter-feature Correlation Matrix')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.yticks(rotation=0)\n",
        "    if save_plots:\n",
        "        plt.savefig(f\"{output_dir}/correlations_heatmap.png\", bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    # Save statistics to CSV\n",
        "    if save_plots:\n",
        "        stats_df.to_csv(f\"{output_dir}/feature_statistics.csv\")\n",
        "        feature_ncde_corr.to_csv(f\"{output_dir}/feature_ncde_correlations.csv\")\n",
        "\n",
        "    # Identify highly correlated features\n",
        "    corr_matrix = X.corr()\n",
        "    high_corr_threshold = 0.7\n",
        "    high_corr_pairs = []\n",
        "    for i in range(len(feature_names)):\n",
        "        for j in range(i+1, len(feature_names)):\n",
        "            corr = abs(corr_matrix.iloc[i, j])\n",
        "            if corr > high_corr_threshold and not np.isnan(corr):\n",
        "                high_corr_pairs.append((\n",
        "                    feature_names[i],\n",
        "                    feature_names[j],\n",
        "                    corr\n",
        "                ))\n",
        "\n",
        "    if high_corr_pairs:\n",
        "        print(\"\\nHighly correlated feature pairs (|r| > 0.7):\")\n",
        "        for f1, f2, corr in high_corr_pairs:\n",
        "            print(f\"{f1} - {f2}: {corr:.3f}\")\n",
        "\n",
        "    return {\n",
        "        'statistics': stats_df,\n",
        "        'feature_ncde_correlations': feature_ncde_corr,\n",
        "        'correlation_matrix': corr_matrix,\n",
        "        'high_correlation_pairs': high_corr_pairs\n",
        "    }\n",
        "\n",
        "def analyze_feature_distribution(data, feature_name):\n",
        "    \"\"\"Analyze the distribution of a specific feature in detail.\"\"\"\n",
        "    # Get values and remove NaN values\n",
        "    values = data[feature_name].dropna()\n",
        "\n",
        "    # Basic statistics\n",
        "    stats_dict = {\n",
        "        'count': len(values),\n",
        "        'mean': values.mean(),\n",
        "        'median': values.median(),\n",
        "        'std': values.std(),\n",
        "        'min': values.min(),\n",
        "        'max': values.max(),\n",
        "        'skew': values.skew(),\n",
        "        'kurtosis': values.kurtosis(),\n",
        "        'zeros': (values == 0).sum(),\n",
        "        'unique_values': len(values.unique()),\n",
        "        'missing_values': data[feature_name].isna().sum()\n",
        "    }\n",
        "\n",
        "    # Calculate percentiles\n",
        "    percentiles = [0, 1, 5, 10, 25, 50, 75, 90, 95, 99, 100]\n",
        "    for p in percentiles:\n",
        "        stats_dict[f'p{p}'] = np.nanpercentile(values, p)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\nDetailed Analysis of {feature_name}:\")\n",
        "    print(f\"Count: {stats_dict['count']}\")\n",
        "    print(f\"Missing values: {stats_dict['missing_values']}\")\n",
        "    print(f\"Unique values: {stats_dict['unique_values']}\")\n",
        "    print(f\"Zeros: {stats_dict['zeros']} ({stats_dict['zeros']/stats_dict['count']*100:.1f}%)\")\n",
        "    print(f\"\\nCentral Tendency:\")\n",
        "    print(f\"Mean: {stats_dict['mean']:.6f}\")\n",
        "    print(f\"Median: {stats_dict['median']:.6f}\")\n",
        "    print(f\"Std Dev: {stats_dict['std']:.6f}\")\n",
        "    print(f\"\\nShape:\")\n",
        "    print(f\"Skewness: {stats_dict['skew']:.2f}\")\n",
        "    print(f\"Kurtosis: {stats_dict['kurtosis']:.2f}\")\n",
        "    print(f\"\\nRange:\")\n",
        "    print(f\"Min: {stats_dict['min']:.6f}\")\n",
        "    print(f\"Max: {stats_dict['max']:.6f}\")\n",
        "\n",
        "    print(\"\\nPercentiles:\")\n",
        "    for p in percentiles:\n",
        "        print(f\"p{p}: {stats_dict[f'p{p}']:.6f}\")\n",
        "\n",
        "    # Create visualization\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Histogram with density\n",
        "    plt.subplot(131)\n",
        "    sns.histplot(data=values, kde=True)\n",
        "    plt.title(f'Distribution of {feature_name}')\n",
        "    plt.xlabel(feature_name)\n",
        "\n",
        "    # Box plot\n",
        "    plt.subplot(132)\n",
        "    sns.boxplot(y=values)\n",
        "    plt.title(f'Box Plot of {feature_name}')\n",
        "\n",
        "    # Q-Q plot\n",
        "    plt.subplot(133)\n",
        "    from scipy import stats as scipy_stats\n",
        "    scipy_stats.probplot(values, dist=\"norm\", plot=plt)\n",
        "    plt.title(f'Q-Q Plot of {feature_name}')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'feature_analysis/{feature_name}_detailed_analysis.png')\n",
        "    plt.close()\n",
        "\n",
        "    return stats_dict\n",
        "\n",
        "# If the script is run directly, show the example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Get the data in the new format\n",
        "    data_dict = load_and_process_data(verbose=True)\n",
        "\n",
        "    # Run the feature analysis\n",
        "    analysis = analyze_features(data_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SijkIRW6T3-"
      },
      "source": [
        "Training NAMs and picking the best one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WD0-Urxgzu5H",
        "outputId": "49ffcfa5-0102-452d-c4d8-fdc736dbb34f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. Loading data...\n",
            "\n",
            "fysh:\n",
            "  Original skewness: 2.1691698429431523\n",
            "  Transformation results:\n",
            "    log1p: -1.37\n",
            "    power: -0.41\n",
            "    rank: 0.00\n",
            "  Selected: rank (skewness: 0.00)\n",
            "\n",
            "ρsh:\n",
            "  Original skewness: 5.072272455267313\n",
            "  Transformation results:\n",
            "    log1p: 4.87\n",
            "    power: 0.43\n",
            "    rank: 0.00\n",
            "  Selected: rank (skewness: 0.00)\n",
            "\n",
            "Analyzing ρsh distribution before transformation:\n",
            "\n",
            "Detailed Analysis of ρsh:\n",
            "Count: 216\n",
            "Missing values: 96\n",
            "Unique values: 113\n",
            "Zeros: 0 (0.0%)\n",
            "\n",
            "Central Tendency:\n",
            "Mean: 0.009859\n",
            "Median: 0.008177\n",
            "Std Dev: 0.009038\n",
            "\n",
            "Shape:\n",
            "Skewness: 5.07\n",
            "Kurtosis: 40.30\n",
            "\n",
            "Range:\n",
            "Min: 0.000950\n",
            "Max: 0.095700\n",
            "\n",
            "Percentiles:\n",
            "p0: 0.000950\n",
            "p1: 0.001340\n",
            "p5: 0.002248\n",
            "p10: 0.002513\n",
            "p25: 0.005309\n",
            "p50: 0.008177\n",
            "p75: 0.011166\n",
            "p90: 0.016956\n",
            "p95: 0.023020\n",
            "p99: 0.042834\n",
            "p100: 0.095700\n",
            "\n",
            "2. Initializing NAM analyzer...\n",
            "Using device: cpu\n",
            "\n",
            "3. Running grid search...\n",
            "\n",
            "Testing configuration 1/16:\n",
            "{\n",
            "  \"hidden_layers\": [\n",
            "    64,\n",
            "    128\n",
            "  ],\n",
            "  \"learning_rate\": 0.001,\n",
            "  \"batch_size\": 32\n",
            "}\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def optimize_nam():\n",
        "    # Set random seeds for reproducibility\n",
        "    torch.manual_seed(42)\n",
        "    np.random.seed(42)\n",
        "\n",
        "    print(\"1. Loading data...\")\n",
        "    data_dict = load_and_process_data(verbose=False)\n",
        "\n",
        "    print(\"\\n2. Initializing NAM analyzer...\")\n",
        "    analyzer = NAMAnalyzer(data_dict)\n",
        "\n",
        "    print(\"\\n3. Running grid search...\")\n",
        "    # Define parameter grid for the new NAM architecture\n",
        "    param_grid = {\n",
        "        'hidden_layers': [\n",
        "            [64, 128],      # Two layers: medium -> large\n",
        "            [128, 64],      # Two layers: large -> medium (bottleneck)\n",
        "            [64],           # Single medium layer\n",
        "            [128]           # Single large layer\n",
        "        ],\n",
        "        'learning_rate': [0.001, 0.0005],\n",
        "        'batch_size': [32, 64]\n",
        "    }\n",
        "\n",
        "    results = analyzer.grid_search(param_grid)\n",
        "\n",
        "    print(\"\\n4. Analyzing best model...\")\n",
        "    analyzer.analyze_best_model()\n",
        "\n",
        "    print(\"\\nOptimization completed successfully!\")\n",
        "\n",
        "optimize_nam()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UzNI-zW9MfH"
      },
      "source": [
        "Training Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ihUejR81YAx",
        "outputId": "31fd2ec9-c6ab-413a-8545-04ad7bd52451"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_model(model, X_train, X_test, y_train, y_test, y_scaler):\n",
        "    \"\"\"Train a model and evaluate its performance.\"\"\"\n",
        "    # Train the model\n",
        "    model.fit(X_train, y_train.values.ravel())\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Convert predictions back to original scale\n",
        "    y_pred_orig = y_scaler.inverse_transform(y_pred.reshape(-1, 1)).reshape(-1)\n",
        "    y_true_orig = y_scaler.inverse_transform(y_test.values).reshape(-1)\n",
        "\n",
        "    # Calculate metrics\n",
        "    metrics = {\n",
        "        'rmse': float(np.sqrt(mean_squared_error(y_true_orig, y_pred_orig))),\n",
        "        'mae': float(mean_absolute_error(y_true_orig, y_pred_orig)),\n",
        "        'r2': float(r2_score(y_true_orig, y_pred_orig)),\n",
        "        'explained_variance': float(explained_variance_score(y_true_orig, y_pred_orig))\n",
        "    }\n",
        "\n",
        "    return metrics\n",
        "\n",
        "def optimize_random_forest():\n",
        "    \"\"\"Optimize Random Forest model.\"\"\"\n",
        "    param_grid = [\n",
        "        {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2},\n",
        "        {'n_estimators': 200, 'max_depth': 15, 'min_samples_split': 5},\n",
        "        {'n_estimators': 300, 'max_depth': None, 'min_samples_split': 10}\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    best_metrics = {'r2': float('-inf')}\n",
        "    best_model = None\n",
        "\n",
        "    for params in param_grid:\n",
        "        model = RandomForestRegressor(\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            **params\n",
        "        )\n",
        "        metrics = train_and_evaluate_model(model, X_train, X_test, y_train, y_test, y_scaler)\n",
        "\n",
        "        result = {\n",
        "            'model_type': 'RandomForest',\n",
        "            'params': params,\n",
        "            'metrics': metrics\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        if metrics['r2'] > best_metrics['r2']:\n",
        "            best_metrics = metrics\n",
        "            best_model = model\n",
        "\n",
        "    return results, best_model\n",
        "\n",
        "def optimize_xgboost():\n",
        "    \"\"\"Optimize XGBoost model.\"\"\"\n",
        "    param_grid = [\n",
        "        {'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1},\n",
        "        {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.05},\n",
        "        {'n_estimators': 500, 'max_depth': 30, 'learning_rate': 0.01}\n",
        "    ]\n",
        "\n",
        "    results = []\n",
        "    best_metrics = {'r2': float('-inf')}\n",
        "    best_model = None\n",
        "\n",
        "    for params in param_grid:\n",
        "        model = XGBRegressor(\n",
        "            random_state=42,\n",
        "            n_jobs=-1,\n",
        "            **params\n",
        "        )\n",
        "        metrics = train_and_evaluate_model(model, X_train, X_test, y_train, y_test, y_scaler)\n",
        "\n",
        "        result = {\n",
        "            'model_type': 'XGBoost',\n",
        "            'params': params,\n",
        "            'metrics': metrics\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "        if metrics['r2'] > best_metrics['r2']:\n",
        "            best_metrics = metrics\n",
        "            best_model = model\n",
        "\n",
        "    return results, best_model\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    data_dict = load_and_process_data(verbose=False)\n",
        "\n",
        "    # Extract data\n",
        "    X_train = data_dict['X_train']\n",
        "    X_test = data_dict['X_test']\n",
        "    y_train = data_dict['y_train']\n",
        "    y_test = data_dict['y_test']\n",
        "    y_scaler = data_dict['y_scaler']\n",
        "\n",
        "    # Create results directory\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    results_dir = f'baseline_results_{timestamp}'\n",
        "    os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "    # Optimize Random Forest\n",
        "    print(\"\\nOptimizing Random Forest...\")\n",
        "    rf_results, best_rf = optimize_random_forest()\n",
        "\n",
        "    # Optimize XGBoost\n",
        "    print(\"\\nOptimizing XGBoost...\")\n",
        "    xgb_results, best_xgb = optimize_xgboost()\n",
        "\n",
        "    # Combine results\n",
        "    all_results = rf_results + xgb_results\n",
        "\n",
        "    # Save results\n",
        "    print(\"\\nSaving results...\")\n",
        "    results_file = f'{results_dir}/baseline_results.json'\n",
        "    with open(results_file, 'w') as f:\n",
        "        json.dump(all_results, f, indent=2)\n",
        "\n",
        "    # Save best models\n",
        "    joblib.dump(best_rf, f'{results_dir}/best_random_forest.joblib')\n",
        "    joblib.dump(best_xgb, f'{results_dir}/best_xgboost.joblib')\n",
        "\n",
        "    # Print best results\n",
        "    print(\"\\nRandom Forest Results:\")\n",
        "    for result in rf_results:\n",
        "        print(f\"\\nParameters: {result['params']}\")\n",
        "        print(f\"Metrics: {result['metrics']}\")\n",
        "\n",
        "    print(\"\\nXGBoost Results:\")\n",
        "    for result in xgb_results:\n",
        "        print(f\"\\nParameters: {result['params']}\")\n",
        "        print(f\"Metrics: {result['metrics']}\")\n",
        "\n",
        "    print(f\"\\nResults and models saved in: {results_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSrlauYg7X-k",
        "outputId": "cf01b21a-2fed-45a4-e10a-68c60ff740b9"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from analyze_best_models import find_latest_results_dir as find_nam_dir\n",
        "\n",
        "def find_latest_baseline_dir():\n",
        "    \"\"\"Find the most recent baseline results directory.\"\"\"\n",
        "    dirs = [d for d in os.listdir('.') if d.startswith('baseline_results_')]\n",
        "    if not dirs:\n",
        "        raise ValueError(\"No baseline results directory found!\")\n",
        "    return sorted(dirs)[-1]\n",
        "\n",
        "def load_best_models():\n",
        "    \"\"\"Load the best models and their results.\"\"\"\n",
        "    # Load NAM results\n",
        "    nam_dir = find_nam_dir()\n",
        "    with open(f'{nam_dir}/all_results.json', 'r') as f:\n",
        "        nam_results = json.load(f)\n",
        "\n",
        "    # Handle different metrics structure in NAM results\n",
        "    def get_metrics(result):\n",
        "        if 'test_metrics' in result['metrics']:  # Old NAM format\n",
        "            return result['metrics']['test_metrics']\n",
        "        return result['metrics']  # New format (baselines)\n",
        "\n",
        "    best_nam = sorted(nam_results, key=lambda x: get_metrics(x)['r2'], reverse=True)[0]\n",
        "\n",
        "    # Load baseline results\n",
        "    baseline_dir = find_latest_baseline_dir()\n",
        "    with open(f'{baseline_dir}/baseline_results.json', 'r') as f:\n",
        "        baseline_results = json.load(f)\n",
        "\n",
        "    # Load best baseline models\n",
        "    best_rf = joblib.load(f'{baseline_dir}/best_random_forest.joblib')\n",
        "    best_xgb = joblib.load(f'{baseline_dir}/best_xgboost.joblib')\n",
        "\n",
        "    # Get best results for each model type\n",
        "    rf_results = [r for r in baseline_results if r['model_type'] == 'RandomForest']\n",
        "    xgb_results = [r for r in baseline_results if r['model_type'] == 'XGBoost']\n",
        "    best_rf_result = sorted(rf_results, key=lambda x: x['metrics']['r2'], reverse=True)[0]\n",
        "    best_xgb_result = sorted(xgb_results, key=lambda x: x['metrics']['r2'], reverse=True)[0]\n",
        "\n",
        "    return {\n",
        "        'NAM': {'result': {'params': best_nam['params'], 'metrics': get_metrics(best_nam)}},\n",
        "        'RandomForest': {'model': best_rf, 'result': best_rf_result},\n",
        "        'XGBoost': {'model': best_xgb, 'result': best_xgb_result}\n",
        "    }\n",
        "\n",
        "def plot_model_comparison(models_dict):\n",
        "    \"\"\"Create comparison plots for all models.\"\"\"\n",
        "    # Set up the plot style\n",
        "    plt.rcParams['figure.figsize'] = (15, 10)\n",
        "    plt.rcParams['font.size'] = 10\n",
        "\n",
        "    # Create figure\n",
        "    fig = plt.figure()\n",
        "\n",
        "    # Extract metrics\n",
        "    model_names = list(models_dict.keys())\n",
        "    metrics = {\n",
        "        'R²': [models_dict[m]['result']['metrics']['r2'] for m in model_names],\n",
        "        'RMSE': [models_dict[m]['result']['metrics']['rmse'] for m in model_names],\n",
        "        'MAE': [models_dict[m]['result']['metrics']['mae'] for m in model_names],\n",
        "        'Explained Variance': [models_dict[m]['result']['metrics']['explained_variance'] for m in model_names]\n",
        "    }\n",
        "\n",
        "    # Color scheme\n",
        "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "    # Create subplots for each metric\n",
        "    for i, (metric_name, values) in enumerate(metrics.items(), 1):\n",
        "        plt.subplot(2, 2, i)\n",
        "        bars = plt.bar(model_names, values, color=colors)\n",
        "        plt.title(f'{metric_name} Comparison', pad=20)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.4f}',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def print_detailed_comparison(models_dict):\n",
        "    \"\"\"Print detailed comparison of all models.\"\"\"\n",
        "    print(\"\\n=== Model Comparison ===\")\n",
        "    print(\"\\nBest Model Configurations:\")\n",
        "\n",
        "    for model_name, model_info in models_dict.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(\"Parameters:\")\n",
        "        print(json.dumps(model_info['result']['params'], indent=2))\n",
        "        print(\"\\nMetrics:\")\n",
        "        metrics = model_info['result']['metrics']\n",
        "        print(f\"R²: {metrics['r2']:.4f}\")\n",
        "        print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
        "        print(f\"MAE: {metrics['mae']:.4f}\")\n",
        "        print(f\"Explained Variance: {metrics['explained_variance']:.4f}\")\n",
        "\n",
        "    # Find the best model\n",
        "    best_model = max(models_dict.items(), key=lambda x: x[1]['result']['metrics']['r2'])\n",
        "    print(f\"\\n🏆 Best Overall Model: {best_model[0]}\")\n",
        "    print(f\"R² Score: {best_model[1]['result']['metrics']['r2']:.4f}\")\n",
        "\n",
        "def main():\n",
        "    print(\"Loading best models and results...\")\n",
        "    models_dict = load_best_models()\n",
        "\n",
        "    print(\"\\nCreating comparison plots...\")\n",
        "    plot_model_comparison(models_dict)\n",
        "\n",
        "    print(\"\\nGenerating detailed comparison...\")\n",
        "    print_detailed_comparison(models_dict)\n",
        "\n",
        "    print(\"\\nComparison plot saved as 'model_comparison.png'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bT3p3aL4No4O",
        "outputId": "26d34bac-212a-4bd3-b63b-9cf8b851f1df"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from analyze_database import load_and_process_data\n",
        "from analyze_best_models import find_latest_results_dir as find_nam_dir\n",
        "import scipy.stats as stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "import torch\n",
        "from nam_analysis import NAM\n",
        "from analyze_database import FEATURE_DICT\n",
        "\n",
        "def find_latest_baseline_dir():\n",
        "    \"\"\"Find the most recent baseline results directory.\"\"\"\n",
        "    dirs = [d for d in os.listdir('.') if d.startswith('baseline_results_')]\n",
        "    if not dirs:\n",
        "        raise ValueError(\"No baseline results directory found!\")\n",
        "    return sorted(dirs)[-1]\n",
        "\n",
        "def load_best_models():\n",
        "    \"\"\"Load the best models and their results.\"\"\"\n",
        "    # Load NAM results\n",
        "    nam_dir = find_nam_dir()\n",
        "    with open(f'{nam_dir}/all_results.json', 'r') as f:\n",
        "        nam_results = json.load(f)\n",
        "\n",
        "    # Handle different metrics structure in NAM results\n",
        "    def get_metrics(result):\n",
        "        if 'test_metrics' in result['metrics']:  # Old NAM format\n",
        "            return result['metrics']['test_metrics']\n",
        "        return result['metrics']  # New format (baselines)\n",
        "\n",
        "    best_nam = sorted(nam_results, key=lambda x: get_metrics(x)['r2'], reverse=True)[0]\n",
        "\n",
        "    # Load baseline results\n",
        "    baseline_dir = find_latest_baseline_dir()\n",
        "    with open(f'{baseline_dir}/baseline_results.json', 'r') as f:\n",
        "        baseline_results = json.load(f)\n",
        "\n",
        "    # Load best baseline models\n",
        "    best_rf = joblib.load(f'{baseline_dir}/best_random_forest.joblib')\n",
        "    best_xgb = joblib.load(f'{baseline_dir}/best_xgboost.joblib')\n",
        "\n",
        "    # Get best results for each model type\n",
        "    rf_results = [r for r in baseline_results if r['model_type'] == 'RandomForest']\n",
        "    xgb_results = [r for r in baseline_results if r['model_type'] == 'XGBoost']\n",
        "    best_rf_result = sorted(rf_results, key=lambda x: x['metrics']['r2'], reverse=True)[0]\n",
        "    best_xgb_result = sorted(xgb_results, key=lambda x: x['metrics']['r2'], reverse=True)[0]\n",
        "\n",
        "    return {\n",
        "        'NAM': {'result': {'params': best_nam['params'], 'metrics': get_metrics(best_nam)}},\n",
        "        'RandomForest': {'model': best_rf, 'result': best_rf_result},\n",
        "        'XGBoost': {'model': best_xgb, 'result': best_xgb_result}\n",
        "    }\n",
        "\n",
        "def plot_model_comparison(models_dict):\n",
        "    \"\"\"Create comparison plots for all models.\"\"\"\n",
        "    # Set up the plot style\n",
        "    plt.rcParams['figure.figsize'] = (15, 10)\n",
        "    plt.rcParams['font.size'] = 10\n",
        "\n",
        "    # Create figure\n",
        "    fig = plt.figure()\n",
        "\n",
        "    # Extract metrics\n",
        "    model_names = list(models_dict.keys())\n",
        "    metrics = {\n",
        "        'R²': [models_dict[m]['result']['metrics']['r2'] for m in model_names],\n",
        "        'RMSE': [models_dict[m]['result']['metrics']['rmse'] for m in model_names],\n",
        "        'MAE': [models_dict[m]['result']['metrics']['mae'] for m in model_names],\n",
        "        'Explained Variance': [models_dict[m]['result']['metrics']['explained_variance'] for m in model_names]\n",
        "    }\n",
        "\n",
        "    # Color scheme\n",
        "    colors = ['#2ecc71', '#3498db', '#e74c3c']\n",
        "\n",
        "    # Create subplots for each metric\n",
        "    for i, (metric_name, values) in enumerate(metrics.items(), 1):\n",
        "        plt.subplot(2, 2, i)\n",
        "        bars = plt.bar(model_names, values, color=colors)\n",
        "        plt.title(f'{metric_name} Comparison', pad=20)\n",
        "        plt.xticks(rotation=45)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Add value labels on top of bars\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                    f'{height:.4f}',\n",
        "                    ha='center', va='bottom')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('model_comparison.png', dpi=300, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def print_detailed_comparison(models_dict):\n",
        "    \"\"\"Print detailed comparison of all models.\"\"\"\n",
        "    print(\"\\n=== Model Comparison ===\")\n",
        "    print(\"\\nBest Model Configurations:\")\n",
        "\n",
        "    for model_name, model_info in models_dict.items():\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(\"Parameters:\")\n",
        "        print(json.dumps(model_info['result']['params'], indent=2))\n",
        "        print(\"\\nMetrics:\")\n",
        "        metrics = model_info['result']['metrics']\n",
        "        print(f\"R²: {metrics['r2']:.4f}\")\n",
        "        print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
        "        print(f\"MAE: {metrics['mae']:.4f}\")\n",
        "        print(f\"Explained Variance: {metrics['explained_variance']:.4f}\")\n",
        "\n",
        "    # Find the best model\n",
        "    best_model = max(models_dict.items(), key=lambda x: x[1]['result']['metrics']['r2'])\n",
        "    print(f\"\\n🏆 Best Overall Model: {best_model[0]}\")\n",
        "    print(f\"R² Score: {best_model[1]['result']['metrics']['r2']:.4f}\")\n",
        "\n",
        "def load_model_predictions(data_dict):\n",
        "    \"\"\"Load predictions from all three models.\"\"\"\n",
        "    # Apply transformations to test data if needed\n",
        "    X_test = data_dict['X_test'].copy()\n",
        "    if 'transformations' in data_dict:\n",
        "        for feature, info in data_dict['transformations'].items():\n",
        "            if info['type'] == 'log1p':\n",
        "                X_test[feature] = np.log1p(X_test[feature] + info['params']['offset'])\n",
        "            elif info['type'] == 'power':\n",
        "                X_test[feature] = np.power(X_test[feature] + info['params']['offset'],\n",
        "                                         info['params']['power'])\n",
        "            elif info['type'] == 'rank':\n",
        "                X_test[feature] = X_test[feature].rank(pct=True)\n",
        "\n",
        "    # Load NAM predictions\n",
        "    nam_dirs = [d for d in os.listdir('.') if d.startswith('nam_results_')]\n",
        "    if not nam_dirs:\n",
        "        raise FileNotFoundError(\"No NAM results directory found\")\n",
        "    latest_nam_dir = max(nam_dirs)\n",
        "\n",
        "    # Load NAM model\n",
        "    checkpoint = torch.load(os.path.join(latest_nam_dir, 'best_model.pt'), weights_only=False)\n",
        "    model_state = checkpoint['model_state_dict']\n",
        "    params = checkpoint['params']\n",
        "\n",
        "    nam_model = NAM(num_features=len(FEATURE_DICT), hidden_layers=params['hidden_layers'])\n",
        "    nam_model.load_state_dict(model_state)\n",
        "    nam_model.eval()\n",
        "\n",
        "    # Get NAM predictions\n",
        "    X_test_tensor = torch.FloatTensor(X_test.to_numpy())\n",
        "    with torch.no_grad():\n",
        "        nam_preds = nam_model(X_test_tensor)\n",
        "        if isinstance(nam_preds, tuple):\n",
        "            nam_preds = nam_preds[0]  # Get the main output if tuple\n",
        "        nam_preds = nam_preds.cpu().numpy()\n",
        "\n",
        "    # Find latest baseline directory\n",
        "    baseline_dirs = [d for d in os.listdir('.') if d.startswith('baseline_results_')]\n",
        "    if not baseline_dirs:\n",
        "        raise FileNotFoundError(\"No baseline results directory found\")\n",
        "    latest_baseline_dir = max(baseline_dirs)\n",
        "\n",
        "    # Load RF and XGB models from the baseline directory\n",
        "    rf_model = joblib.load(os.path.join(latest_baseline_dir, 'best_random_forest.joblib'))\n",
        "    xgb_model = joblib.load(os.path.join(latest_baseline_dir, 'best_xgboost.joblib'))\n",
        "\n",
        "    # Get RF and XGB predictions\n",
        "    rf_preds = rf_model.predict(X_test)\n",
        "    xgb_preds = xgb_model.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions to original scale\n",
        "    y_scaler = data_dict['y_scaler']\n",
        "    nam_preds = y_scaler.inverse_transform(nam_preds.reshape(-1, 1)).flatten()\n",
        "    rf_preds = y_scaler.inverse_transform(rf_preds.reshape(-1, 1)).flatten()\n",
        "    xgb_preds = y_scaler.inverse_transform(xgb_preds.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Get true values\n",
        "    y_true = y_scaler.inverse_transform(data_dict['y_test'].values).flatten()\n",
        "\n",
        "    return nam_preds, rf_preds, xgb_preds, y_true\n",
        "\n",
        "def perform_model_anova(nam_preds, rf_preds, xgb_preds, y_true, output_dir=\"model_analysis\"):\n",
        "    \"\"\"\n",
        "    Perform ANOVA and post-hoc tests to compare model predictions.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    nam_preds : array-like\n",
        "        Predictions from NAM model\n",
        "    rf_preds : array-like\n",
        "        Predictions from Random Forest model\n",
        "    xgb_preds : array-like\n",
        "        Predictions from XGBoost model\n",
        "    y_true : array-like\n",
        "        True target values\n",
        "    output_dir : str, default=\"model_analysis\"\n",
        "        Directory to save analysis results\n",
        "    \"\"\"\n",
        "    # Create output directory\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Calculate residuals\n",
        "    nam_residuals = y_true - nam_preds\n",
        "    rf_residuals = y_true - rf_preds\n",
        "    xgb_residuals = y_true - xgb_preds\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    def calc_metrics(y_true, y_pred):\n",
        "        residuals = y_true - y_pred\n",
        "        mse = np.mean(residuals ** 2)\n",
        "        rmse = np.sqrt(mse)\n",
        "        mae = np.mean(np.abs(residuals))\n",
        "        r2 = 1 - np.sum(residuals ** 2) / np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "        return {'RMSE': rmse, 'MAE': mae, 'R²': r2}\n",
        "\n",
        "    nam_metrics = calc_metrics(y_true, nam_preds)\n",
        "    rf_metrics = calc_metrics(y_true, rf_preds)\n",
        "    xgb_metrics = calc_metrics(y_true, xgb_preds)\n",
        "\n",
        "    # Prepare data for ANOVA\n",
        "    all_residuals = np.concatenate([nam_residuals, rf_residuals, xgb_residuals])\n",
        "    model_labels = np.repeat(['NAM', 'RF', 'XGB'], [len(nam_residuals), len(rf_residuals), len(xgb_residuals)])\n",
        "\n",
        "    # Perform one-way ANOVA\n",
        "    f_stat, p_value = stats.f_oneway(nam_residuals, rf_residuals, xgb_residuals)\n",
        "\n",
        "    # Perform Tukey's HSD test\n",
        "    tukey = pairwise_tukeyhsd(all_residuals, model_labels)\n",
        "\n",
        "    # Calculate additional statistics\n",
        "    model_stats = pd.DataFrame({\n",
        "        'Model': ['NAM', 'RF', 'XGB'],\n",
        "        'Mean Residual': [np.mean(nam_residuals), np.mean(rf_residuals), np.mean(xgb_residuals)],\n",
        "        'Std Residual': [np.std(nam_residuals), np.std(rf_residuals), np.std(xgb_residuals)],\n",
        "        'Mean Abs Residual': [np.mean(np.abs(nam_residuals)),\n",
        "                            np.mean(np.abs(rf_residuals)),\n",
        "                            np.mean(np.abs(xgb_residuals))],\n",
        "        'Median Residual': [np.median(nam_residuals), np.median(rf_residuals), np.median(xgb_residuals)],\n",
        "        'RMSE': [nam_metrics['RMSE'], rf_metrics['RMSE'], xgb_metrics['RMSE']],\n",
        "        'MAE': [nam_metrics['MAE'], rf_metrics['MAE'], xgb_metrics['MAE']],\n",
        "        'R²': [nam_metrics['R²'], rf_metrics['R²'], xgb_metrics['R²']]\n",
        "    })\n",
        "\n",
        "    # Create visualization of residuals\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Box plots\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.boxplot(x=model_labels, y=all_residuals)\n",
        "    plt.title('Residual Distribution by Model')\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel('Residual')\n",
        "\n",
        "    # Violin plots\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.violinplot(x=model_labels, y=all_residuals)\n",
        "    plt.title('Residual Density by Model')\n",
        "    plt.xlabel('Model')\n",
        "    plt.ylabel('Residual')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'residual_analysis.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Create Q-Q plots for each model's residuals\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    stats.probplot(nam_residuals, dist=\"norm\", plot=axes[0])\n",
        "    axes[0].set_title('NAM Q-Q Plot')\n",
        "\n",
        "    stats.probplot(rf_residuals, dist=\"norm\", plot=axes[1])\n",
        "    axes[1].set_title('RF Q-Q Plot')\n",
        "\n",
        "    stats.probplot(xgb_residuals, dist=\"norm\", plot=axes[2])\n",
        "    axes[2].set_title('XGB Q-Q Plot')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'residual_qq_plots.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Create scatter plots of predicted vs actual values\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    axes[0].scatter(nam_preds, y_true, alpha=0.5)\n",
        "    axes[0].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
        "    axes[0].set_title(f'NAM (R² = {nam_metrics[\"R²\"]:.3f})')\n",
        "    axes[0].set_xlabel('Predicted')\n",
        "    axes[0].set_ylabel('Actual')\n",
        "\n",
        "    axes[1].scatter(rf_preds, y_true, alpha=0.5)\n",
        "    axes[1].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
        "    axes[1].set_title(f'Random Forest (R² = {rf_metrics[\"R²\"]:.3f})')\n",
        "    axes[1].set_xlabel('Predicted')\n",
        "    axes[1].set_ylabel('Actual')\n",
        "\n",
        "    axes[2].scatter(xgb_preds, y_true, alpha=0.5)\n",
        "    axes[2].plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'r--')\n",
        "    axes[2].set_title(f'XGBoost (R² = {xgb_metrics[\"R²\"]:.3f})')\n",
        "    axes[2].set_xlabel('Predicted')\n",
        "    axes[2].set_ylabel('Actual')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'prediction_scatter_plots.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Generate HTML report\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>Model Comparison Analysis</title>\n",
        "        <style>\n",
        "            body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
        "            .section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; }}\n",
        "            .plot {{ text-align: center; margin: 20px 0; }}\n",
        "            table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}\n",
        "            th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}\n",
        "            th {{ background-color: #f5f5f5; }}\n",
        "            .highlight {{ background-color: #fff3cd; }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>Model Comparison Analysis</h1>\n",
        "\n",
        "        <div class=\"section\">\n",
        "            <h2>1. Performance Metrics</h2>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>Model</th>\n",
        "                    <th>RMSE</th>\n",
        "                    <th>MAE</th>\n",
        "                    <th>R²</th>\n",
        "                </tr>\n",
        "    \"\"\"\n",
        "\n",
        "    for _, row in model_stats.iterrows():\n",
        "        html_content += f\"\"\"\n",
        "                <tr>\n",
        "                    <td>{row['Model']}</td>\n",
        "                    <td>{row['RMSE']:.4f}</td>\n",
        "                    <td>{row['MAE']:.4f}</td>\n",
        "                    <td>{row['R²']:.4f}</td>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "    html_content += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"section\">\n",
        "            <h2>2. ANOVA Results</h2>\n",
        "            <p>F-statistic: {f_stat:.4f}</p>\n",
        "            <p>p-value: {p_value:.4f}</p>\n",
        "            <p>Interpretation: {'There are significant differences between models' if p_value < 0.05\n",
        "                              else 'No significant differences between models'}</p>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"section\">\n",
        "            <h2>3. Tukey's HSD Test Results</h2>\n",
        "            <pre>{str(tukey)}</pre>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"section\">\n",
        "            <h2>4. Residual Analysis</h2>\n",
        "            <table>\n",
        "                <tr>\n",
        "                    <th>Model</th>\n",
        "                    <th>Mean Residual</th>\n",
        "                    <th>Std Residual</th>\n",
        "                    <th>Mean Abs Residual</th>\n",
        "                    <th>Median Residual</th>\n",
        "                </tr>\n",
        "    \"\"\"\n",
        "\n",
        "    for _, row in model_stats.iterrows():\n",
        "        html_content += f\"\"\"\n",
        "                <tr>\n",
        "                    <td>{row['Model']}</td>\n",
        "                    <td>{row['Mean Residual']:.4f}</td>\n",
        "                    <td>{row['Std Residual']:.4f}</td>\n",
        "                    <td>{row['Mean Abs Residual']:.4f}</td>\n",
        "                    <td>{row['Median Residual']:.4f}</td>\n",
        "                </tr>\n",
        "        \"\"\"\n",
        "\n",
        "    html_content += \"\"\"\n",
        "            </table>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"section\">\n",
        "            <h2>5. Visualization</h2>\n",
        "            <div class=\"plot\">\n",
        "                <h3>Residual Analysis</h3>\n",
        "                <img src=\"residual_analysis.png\" alt=\"Residual Analysis\">\n",
        "            </div>\n",
        "            <div class=\"plot\">\n",
        "                <h3>Q-Q Plots</h3>\n",
        "                <img src=\"residual_qq_plots.png\" alt=\"Q-Q Plots\">\n",
        "            </div>\n",
        "            <div class=\"plot\">\n",
        "                <h3>Prediction Scatter Plots</h3>\n",
        "                <img src=\"prediction_scatter_plots.png\" alt=\"Prediction Scatter Plots\">\n",
        "            </div>\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    with open(os.path.join(output_dir, 'model_comparison.html'), 'w') as f:\n",
        "        f.write(html_content)\n",
        "\n",
        "    return {\n",
        "        'f_statistic': f_stat,\n",
        "        'p_value': p_value,\n",
        "        'tukey_results': tukey,\n",
        "        'model_stats': model_stats\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    print(\"Loading best models and results...\")\n",
        "    models_dict = load_best_models()\n",
        "\n",
        "    print(\"\\nCreating comparison plots...\")\n",
        "    plot_model_comparison(models_dict)\n",
        "\n",
        "    print(\"\\nGenerating detailed comparison...\")\n",
        "    print_detailed_comparison(models_dict)\n",
        "\n",
        "    print(\"\\nComparison plot saved as 'model_comparison.png'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    data_dict = load_and_process_data(verbose=False)\n",
        "\n",
        "    # Load model predictions and perform ANOVA\n",
        "    print(\"\\nPerforming model comparison analysis...\")\n",
        "    nam_preds, rf_preds, xgb_preds, y_true = load_model_predictions(data_dict)\n",
        "    model_comparison = perform_model_anova(nam_preds, rf_preds, xgb_preds, y_true)\n",
        "\n",
        "    print(\"\\nANOVA Results:\")\n",
        "    print(f\"F-statistic: {model_comparison['f_statistic']:.4f}\")\n",
        "    print(f\"p-value: {model_comparison['p_value']:.4f}\")\n",
        "\n",
        "    print(\"\\nModel Performance Metrics:\")\n",
        "    print(model_comparison['model_stats'][['Model', 'RMSE', 'MAE', 'R²']].to_string(index=False))\n",
        "\n",
        "    print(\"\\nTukey's HSD Test Results:\")\n",
        "    print(model_comparison['tukey_results'])\n",
        "\n",
        "    print(\"\\nDetailed analysis has been saved to the 'model_analysis' directory.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5B_2wrEEO33"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDE9WjZx_rqX",
        "outputId": "b38c685a-dcbc-43ee-d992-69cbc2d2f640"
      },
      "outputs": [],
      "source": [
        "\n",
        "from analyze_database import load_and_process_data, FEATURE_DICT\n",
        "from nam_analysis import NAM\n",
        "\n",
        "def load_nam_model(results_dir):\n",
        "    \"\"\"Load the trained NAM model.\"\"\"\n",
        "    model_path = os.path.join(results_dir, 'best_model.pt')\n",
        "    if not os.path.exists(model_path):\n",
        "        raise FileNotFoundError(\"NAM model file not found\")\n",
        "\n",
        "    # Load with weights_only=False for compatibility\n",
        "    checkpoint = torch.load(model_path, weights_only=False)\n",
        "    model_state = checkpoint['model_state_dict']\n",
        "    params = checkpoint['params']\n",
        "\n",
        "    # Initialize model with same architecture\n",
        "    model = NAM(num_features=len(FEATURE_DICT), hidden_layers=params['hidden_layers'])\n",
        "    model.load_state_dict(model_state)\n",
        "    model.eval()\n",
        "\n",
        "    return model\n",
        "\n",
        "def get_nam_feature_functions(model, X, feature_names, device='cpu'):\n",
        "    \"\"\"Extract individual feature functions from NAM.\"\"\"\n",
        "    model = model.to(device)\n",
        "    X_tensor = torch.FloatTensor(X.to_numpy()).to(device)\n",
        "\n",
        "    feature_functions = {}\n",
        "    with torch.no_grad():\n",
        "        for i, feature in enumerate(feature_names):\n",
        "            # Get contribution for this feature across all samples\n",
        "            feature_input = X_tensor[:, i].unsqueeze(1)\n",
        "            subnet = model.subnets[i]\n",
        "            contribution = subnet(feature_input).cpu().numpy()\n",
        "\n",
        "            # Store feature values and their contributions\n",
        "            feature_functions[feature] = {\n",
        "                'values': X.iloc[:, i].values,\n",
        "                'contributions': contribution.flatten()\n",
        "            }\n",
        "\n",
        "    return feature_functions\n",
        "\n",
        "def load_shap_values():\n",
        "    \"\"\"Load pre-computed SHAP values.\"\"\"\n",
        "    shap_dir = 'shap_analysis_results'\n",
        "    rf_shap = np.load(os.path.join(shap_dir, 'rf', 'shap_values.npy'))\n",
        "    xgb_shap = np.load(os.path.join(shap_dir, 'xgb', 'shap_values.npy'))\n",
        "    return rf_shap, xgb_shap\n",
        "\n",
        "def compare_feature_importance(nam_functions, rf_shap, xgb_shap, feature_names, output_dir):\n",
        "    \"\"\"Compare feature importance across models.\"\"\"\n",
        "    # Calculate NAM importance (variance of contributions)\n",
        "    nam_importance = []\n",
        "    for feature in feature_names:\n",
        "        contributions = nam_functions[feature]['contributions']\n",
        "        importance = np.var(contributions)\n",
        "        nam_importance.append(importance)\n",
        "\n",
        "    # Calculate SHAP importance (mean absolute value)\n",
        "    rf_importance = np.mean(np.abs(rf_shap), axis=0)\n",
        "    xgb_importance = np.mean(np.abs(xgb_shap), axis=0)\n",
        "\n",
        "    # Normalize importances\n",
        "    nam_importance = nam_importance / np.sum(nam_importance)\n",
        "    rf_importance = rf_importance / np.sum(rf_importance)\n",
        "    xgb_importance = xgb_importance / np.sum(xgb_importance)\n",
        "\n",
        "    # Create comparison plot\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    x = np.arange(len(feature_names))\n",
        "    width = 0.25\n",
        "\n",
        "    plt.bar(x - width, nam_importance, width, label='NAM', color='green', alpha=0.7)\n",
        "    plt.bar(x, rf_importance, width, label='Random Forest', color='blue', alpha=0.7)\n",
        "    plt.bar(x + width, xgb_importance, width, label='XGBoost', color='red', alpha=0.7)\n",
        "\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Normalized Importance')\n",
        "    plt.title('Feature Importance Comparison Across Models')\n",
        "    plt.xticks(x, feature_names, rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(output_dir, 'importance_comparison.png'))\n",
        "    plt.close()\n",
        "\n",
        "    return nam_importance, rf_importance, xgb_importance\n",
        "\n",
        "def compare_feature_effects(nam_functions, rf_shap, xgb_shap, X, feature_names, output_dir):\n",
        "    \"\"\"Compare how each model interprets feature effects.\"\"\"\n",
        "    key_features = ['M/Vlw', 'hw', 'ρsh', 'lw', 'b0']  # Most important features\n",
        "\n",
        "    for feature in key_features:\n",
        "        if feature not in feature_names:\n",
        "            continue\n",
        "\n",
        "        plt.figure(figsize=(15, 5))\n",
        "        feature_idx = feature_names.index(feature)\n",
        "\n",
        "        # Plot NAM function\n",
        "        plt.subplot(1, 3, 1)\n",
        "        values = nam_functions[feature]['values']\n",
        "        contributions = nam_functions[feature]['contributions']\n",
        "        order = np.argsort(values)\n",
        "        plt.scatter(values[order], contributions[order], alpha=0.5, s=20)\n",
        "        plt.plot(values[order], contributions[order], 'g-', alpha=0.7, label='NAM')\n",
        "        plt.title(f'NAM Function\\n{feature}')\n",
        "        plt.xlabel('Feature Value')\n",
        "        plt.ylabel('Contribution')\n",
        "\n",
        "        # Plot RF SHAP values\n",
        "        plt.subplot(1, 3, 2)\n",
        "        shap.dependence_plot(\n",
        "            feature_idx, rf_shap, X,\n",
        "            feature_names=feature_names,\n",
        "            show=False,\n",
        "            ax=plt.gca()\n",
        "        )\n",
        "        plt.title(f'Random Forest SHAP\\n{feature}')\n",
        "\n",
        "        # Plot XGB SHAP values\n",
        "        plt.subplot(1, 3, 3)\n",
        "        shap.dependence_plot(\n",
        "            feature_idx, xgb_shap, X,\n",
        "            feature_names=feature_names,\n",
        "            show=False,\n",
        "            ax=plt.gca()\n",
        "        )\n",
        "        plt.title(f'XGBoost SHAP\\n{feature}')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        safe_feature = feature.replace('/', '_').replace('\\\\', '_')\n",
        "        plt.savefig(os.path.join(output_dir, f'effect_comparison_{safe_feature}.png'))\n",
        "        plt.close()\n",
        "\n",
        "def analyze_directionality(nam_functions, rf_shap, xgb_shap, feature_names):\n",
        "    \"\"\"Analyze if models agree on feature effect directions.\"\"\"\n",
        "    directionality = {}\n",
        "\n",
        "    for feature in feature_names:\n",
        "        feature_idx = feature_names.index(feature)\n",
        "\n",
        "        # NAM directionality (correlation between value and contribution)\n",
        "        nam_values = nam_functions[feature]['values']\n",
        "        nam_contrib = nam_functions[feature]['contributions']\n",
        "        nam_corr = np.corrcoef(nam_values, nam_contrib)[0, 1]\n",
        "\n",
        "        # SHAP directionality (correlation between value and SHAP value)\n",
        "        rf_corr = np.corrcoef(nam_values, rf_shap[:, feature_idx])[0, 1]\n",
        "        xgb_corr = np.corrcoef(nam_values, xgb_shap[:, feature_idx])[0, 1]\n",
        "\n",
        "        directionality[feature] = {\n",
        "            'nam': nam_corr,\n",
        "            'rf': rf_corr,\n",
        "            'xgb': xgb_corr,\n",
        "            'agreement': np.sign(nam_corr) == np.sign(rf_corr) == np.sign(xgb_corr)\n",
        "        }\n",
        "\n",
        "    return directionality\n",
        "\n",
        "def create_html_report(output_dir, feature_names, directionality, nam_imp, rf_imp, xgb_imp):\n",
        "    \"\"\"Create an HTML report with plots and descriptions.\"\"\"\n",
        "    # Format the lists of top features first\n",
        "    nam_top = [feature_names[i] for i in np.argsort(nam_imp)[-5:][::-1]]\n",
        "    rf_top = [feature_names[i] for i in np.argsort(rf_imp)[-5:][::-1]]\n",
        "    xgb_top = [feature_names[i] for i in np.argsort(xgb_imp)[-5:][::-1]]\n",
        "\n",
        "    html_content = f\"\"\"\n",
        "    <html>\n",
        "    <head>\n",
        "        <title>Model Interpretability Comparison</title>\n",
        "        <style>\n",
        "            body {{ font-family: Arial, sans-serif; margin: 40px; }}\n",
        "            .plot-section {{ margin: 20px 0; padding: 20px; border: 1px solid #ddd; }}\n",
        "            .plot {{ text-align: center; }}\n",
        "            .description {{ margin: 20px 0; }}\n",
        "            h2 {{ color: #2c3e50; }}\n",
        "            .feature-section {{ margin: 10px 0; }}\n",
        "            .model-comparison {{ display: flex; justify-content: space-around; }}\n",
        "            .model-box {{\n",
        "                flex: 1;\n",
        "                margin: 10px;\n",
        "                padding: 15px;\n",
        "                border: 1px solid #ddd;\n",
        "                border-radius: 5px;\n",
        "            }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <h1>Model Interpretability Comparison Report</h1>\n",
        "\n",
        "        <div class=\"plot-section\">\n",
        "            <h2>1. Overall Feature Importance Comparison</h2>\n",
        "            <div class=\"plot\">\n",
        "                <img src=\"importance_comparison.png\" alt=\"Feature Importance Comparison\">\n",
        "            </div>\n",
        "            <div class=\"description\">\n",
        "                <p>This plot compares how each model ranks feature importance. Key observations:</p>\n",
        "                <ul>\n",
        "                    <li>NAM top 5: {nam_top}</li>\n",
        "                    <li>RF top 5: {rf_top}</li>\n",
        "                    <li>XGB top 5: {xgb_top}</li>\n",
        "                </ul>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"plot-section\">\n",
        "            <h2>2. Individual Feature Effects</h2>\n",
        "            <p>For key features, we compare how each model interprets their effects:</p>\n",
        "    \"\"\"\n",
        "\n",
        "    # Add key feature comparisons\n",
        "    key_features = ['M/Vlw', 'hw', 'ρsh', 'lw', 'b0']\n",
        "    for feature in key_features:\n",
        "        if feature in feature_names:\n",
        "            safe_feature = feature.replace('/', '_').replace('\\\\', '_')\n",
        "            html_content += f\"\"\"\n",
        "            <div class=\"feature-section\">\n",
        "                <h3>Feature: {feature}</h3>\n",
        "                <div class=\"plot\">\n",
        "                    <img src=\"effect_comparison_{safe_feature}.png\" alt=\"Effect Comparison for {feature}\">\n",
        "                </div>\n",
        "                <div class=\"description\">\n",
        "                    <p>Direction agreement: {'Yes' if directionality[feature]['agreement'] else 'No'}</p>\n",
        "                    <p>Effect direction:</p>\n",
        "                    <ul>\n",
        "                        <li>NAM: {'positive' if directionality[feature]['nam'] > 0 else 'negative'}</li>\n",
        "                        <li>RF: {'positive' if directionality[feature]['rf'] > 0 else 'negative'}</li>\n",
        "                        <li>XGB: {'positive' if directionality[feature]['xgb'] > 0 else 'negative'}</li>\n",
        "                    </ul>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"\n",
        "\n",
        "    # Add model comparison section\n",
        "    html_content += \"\"\"\n",
        "        </div>\n",
        "\n",
        "        <div class=\"plot-section\">\n",
        "            <h2>3. Model Comparison Summary</h2>\n",
        "            <div class=\"model-comparison\">\n",
        "                <div class=\"model-box\">\n",
        "                    <h3>NAM</h3>\n",
        "                    <ul>\n",
        "                        <li>Direct interpretation of feature effects</li>\n",
        "                        <li>Smooth, continuous functions</li>\n",
        "                        <li>No interaction effects</li>\n",
        "                        <li>Best for initial understanding</li>\n",
        "                    </ul>\n",
        "                </div>\n",
        "                <div class=\"model-box\">\n",
        "                    <h3>SHAP (RF & XGB)</h3>\n",
        "                    <ul>\n",
        "                        <li>Captures feature interactions</li>\n",
        "                        <li>Local and global interpretability</li>\n",
        "                        <li>More complex relationships</li>\n",
        "                        <li>Best for detailed analysis</li>\n",
        "                    </ul>\n",
        "                </div>\n",
        "            </div>\n",
        "        </div>\n",
        "\n",
        "        <div class=\"plot-section\">\n",
        "            <h2>4. Engineering Recommendations</h2>\n",
        "            <ul>\n",
        "                <li>Use NAM for initial design decisions and understanding individual parameter effects</li>\n",
        "                <li>Use SHAP for understanding complex interactions and verifying NAM findings</li>\n",
        "                <li>Pay special attention to features where models disagree</li>\n",
        "                <li>Consider both approaches for comprehensive understanding</li>\n",
        "            </ul>\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    \"\"\"\n",
        "\n",
        "    # Write HTML report\n",
        "    with open(os.path.join(output_dir, 'interpretability_report.html'), 'w') as f:\n",
        "        f.write(html_content)\n",
        "\n",
        "def main():\n",
        "    # Create output directory\n",
        "    output_dir = 'interpretability_comparison'\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Load data\n",
        "    print(\"Loading data...\")\n",
        "    data_dict = load_and_process_data(verbose=False)\n",
        "    X_test = data_dict['X_test']\n",
        "    feature_names = data_dict['feature_names']\n",
        "\n",
        "    # Find model directories\n",
        "    nam_dirs = [d for d in os.listdir('.') if d.startswith('nam_results_')]\n",
        "    if not nam_dirs:\n",
        "        raise FileNotFoundError(\"No NAM results directory found\")\n",
        "    latest_nam_dir = max(nam_dirs)\n",
        "\n",
        "    # Load models and compute interpretations\n",
        "    print(\"Loading models and computing interpretations...\")\n",
        "    nam_model = load_nam_model(latest_nam_dir)\n",
        "    nam_functions = get_nam_feature_functions(nam_model, X_test, feature_names)\n",
        "    rf_shap, xgb_shap = load_shap_values()\n",
        "\n",
        "    # Compare feature importance\n",
        "    print(\"\\nComparing feature importance...\")\n",
        "    nam_imp, rf_imp, xgb_imp = compare_feature_importance(\n",
        "        nam_functions, rf_shap, xgb_shap, feature_names, output_dir\n",
        "    )\n",
        "\n",
        "    # Compare feature effects\n",
        "    print(\"Comparing feature effects...\")\n",
        "    compare_feature_effects(\n",
        "        nam_functions, rf_shap, xgb_shap, X_test, feature_names, output_dir\n",
        "    )\n",
        "\n",
        "    # Analyze directionality\n",
        "    print(\"Analyzing effect directionality...\")\n",
        "    directionality = analyze_directionality(\n",
        "        nam_functions, rf_shap, xgb_shap, feature_names\n",
        "    )\n",
        "\n",
        "    # Create HTML report\n",
        "    print(\"\\nGenerating HTML report...\")\n",
        "    create_html_report(output_dir, feature_names, directionality, nam_imp, rf_imp, xgb_imp)\n",
        "\n",
        "    # Print insights\n",
        "    print(\"\\nKey Insights:\")\n",
        "    print(\"\\n1. Feature Importance Agreement:\")\n",
        "    # Get top 5 features by each model\n",
        "    top_5_nam = np.argsort(nam_imp)[-5:]\n",
        "    top_5_rf = np.argsort(rf_imp)[-5:]\n",
        "    top_5_xgb = np.argsort(xgb_imp)[-5:]\n",
        "\n",
        "    print(\"\\nTop 5 Important Features:\")\n",
        "    print(\"NAM:\", [feature_names[i] for i in top_5_nam[::-1]])\n",
        "    print(\"RF: \", [feature_names[i] for i in top_5_rf[::-1]])\n",
        "    print(\"XGB:\", [feature_names[i] for i in top_5_xgb[::-1]])\n",
        "\n",
        "    # Find features where all models agree on direction\n",
        "    print(\"\\n2. Directional Agreement:\")\n",
        "    agreement_features = [f for f, d in directionality.items() if d['agreement']]\n",
        "    print(\"\\nFeatures where all models agree on effect direction:\")\n",
        "    for feature in agreement_features:\n",
        "        direction = \"positive\" if directionality[feature]['nam'] > 0 else \"negative\"\n",
        "        print(f\"- {feature}: {direction} effect\")\n",
        "\n",
        "    # Find features with disagreement\n",
        "    disagreement_features = [f for f, d in directionality.items() if not d['agreement']]\n",
        "    print(\"\\nFeatures with disagreement in effect direction:\")\n",
        "    for feature in disagreement_features:\n",
        "        print(f\"\\n{feature}:\")\n",
        "        print(f\"  NAM: {'positive' if directionality[feature]['nam'] > 0 else 'negative'}\")\n",
        "        print(f\"  RF:  {'positive' if directionality[feature]['rf'] > 0 else 'negative'}\")\n",
        "        print(f\"  XGB: {'positive' if directionality[feature]['xgb'] > 0 else 'negative'}\")\n",
        "\n",
        "    print(f\"\\nDetailed report with plots has been generated at: {output_dir}/interpretability_report.html\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
